{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-Nearest Neighbors (kNN)\n",
    "\n",
    "We use RidingMowers.csv for this lab.\n",
    "\n",
    "## Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GEt to know the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_df = pd.read_csv('CustomerLoan.csv')\n",
    "customer_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get to know the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Numerical_attributes = ['income','score']\n",
    "for i,col in enumerate(Numerical_attributes):\n",
    "    customer_df[col].plot(kind='hist')\n",
    "    plt.title(col)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relationships between the attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_df.plot.scatter(x='income',y='score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_df[Numerical_attributes].corr().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_discretized = pd.cut(customer_df.income, bins = 3)\n",
    "contingency_tbl = pd.crosstab(customer_df.default,income_discretized)\n",
    "probablity_tbl = contingency_tbl/ contingency_tbl.sum()\n",
    "sns.heatmap(probablity_tbl, annot=True, center=0.5 ,cmap=\"Greys\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_discretized = pd.cut(customer_df.score, bins = 3)\n",
    "contingency_tbl = pd.crosstab(customer_df.default,score_discretized)\n",
    "probablity_tbl = contingency_tbl/ contingency_tbl.sum()\n",
    "sns.heatmap(probablity_tbl, annot=True, center=0.5 ,cmap=\"Greys\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is not high correlation between the predictors. That means there are no data redundacy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificaiton Purpose\n",
    "We want to create a classification model to predict defualt or not defaulting of loans based on income and credit score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newCustomer = pd.DataFrame([{'income': 98487, 'score': 785}])\n",
    "newCustomer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "subset = customer_df.loc[customer_df['default']=='Yes']\n",
    "ax.scatter(subset.income, subset.score, marker='o', label='Default-YES', color='C1')\n",
    "\n",
    "subset = customer_df.loc[customer_df['default']=='NO']\n",
    "ax.scatter(subset.income, subset.score, marker='D', label='Default-NO', color='C0')\n",
    "\n",
    "ax.scatter(newCustomer.income, newCustomer.score, marker='*', label='New Customer', color='black', s=150)\n",
    "\n",
    "plt.xlabel('income')  # set x-axis label\n",
    "plt.ylabel('score')  # set y-axis label\n",
    "\n",
    "for _, row in customer_df.iterrows():\n",
    "    ax.annotate(row.Name, (row.income -700, row.score-10))\n",
    "    \n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "\n",
    "ax.legend(handles, labels, loc=4)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data\n",
    "from sklearn import preprocessing\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(customer_df[['income', 'score']])  # Note the use of an array of column names\n",
    "\n",
    "Xs = pd.DataFrame(scaler.transform(customer_df[['income', 'score']]),\n",
    "             columns = ['income', 'score'])\n",
    "y= customer_df.default\n",
    "\n",
    "newCustomer_str = pd.DataFrame(scaler.transform(newCustomer),\n",
    "             columns = ['income', 'score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use k-nearest neighbour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "knn = NearestNeighbors(n_neighbors=3)\n",
    "knn.fit(Xs)\n",
    "distances, indices = knn.kneighbors(newCustomer_str)\n",
    "print(Xs.iloc[indices[0]])  # indices is a list of lists, we are only interested in the first element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(customer_df.iloc[indices[0], :]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3).fit(Xs, y)\n",
    "knn.predict(newCustomer_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second Case Study\n",
    "Who will subscribe for a long term deposit?\n",
    "\n",
    "We will use Customer Subscription.csv from https://www.kaggle.com/rashmiranu/banking-dataset-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_df = pd.read_csv('Customer Subscription.csv')\n",
    "customer_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get to know the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_attributes = ['job','marital','education','default','loan','contact','month',\n",
    "                          'day_of_week','y']\n",
    "for i,col in enumerate(categorical_attributes):\n",
    "    customer_df[col].value_counts().plot(kind='barh')\n",
    "    plt.title(col)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deal with unknowns\n",
    "customer_df.job.replace('unknown',np.nan,inplace=True)\n",
    "customer_df.marital.replace('unknown',np.nan,inplace=True)\n",
    "customer_df.education.replace('unknown',np.nan,inplace=True)\n",
    "customer_df.loan.replace('unknown',np.nan,inplace=True)\n",
    "customer_df.default.replace('unknown',np.nan,inplace=True)\n",
    "customer_df.job.replace('unknown',np.nan,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,col in enumerate(categorical_attributes):\n",
    "    customer_df[col].value_counts().plot(kind='barh')\n",
    "    plt.title(col)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_attributes = ['age','duration','campaign','previous','pdays']\n",
    "for i,col in enumerate(numerical_attributes):\n",
    "    customer_df[col].plot(kind='hist')\n",
    "    plt.title(col)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_df.pdays.replace(999,np.nan,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_df.pdays.plot(kind='hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(customer_df[numerical_attributes])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,col1 in enumerate(categorical_attributes):\n",
    "    for ii,col2 in enumerate(categorical_attributes):\n",
    "        if(col1!=col2):\n",
    "            if(i<ii):\n",
    "                contingency_tbl = pd.crosstab(customer_df[col1],customer_df[col2])\n",
    "                probablity_tbl = contingency_tbl/ contingency_tbl.sum()\n",
    "                sns.heatmap(probablity_tbl, annot=True, center=0.5 ,cmap=\"Greys\")\n",
    "                plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,col1 in enumerate(numerical_attributes):\n",
    "    for ii,col2 in enumerate(categorical_attributes):\n",
    "        col_discretized = pd.cut(customer_df[col1], bins = 3)\n",
    "        contingency_tbl = pd.crosstab(customer_df[col2],col_discretized)\n",
    "        probablity_tbl = contingency_tbl/ contingency_tbl.sum()\n",
    "        sns.heatmap(probablity_tbl, annot=True, center=0.5 ,cmap=\"Greys\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task: Classificaiton\n",
    "\n",
    "We would like to predict the class (subscriber/ no subscriber) of customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_predictors = ['age', 'job', 'marital', 'education', 'default', 'housing', 'loan',\n",
    "       'contact', 'month', 'day_of_week', 'duration', 'campaign', 'pdays',\n",
    "       'previous', 'poutcome']\n",
    "target = 'y'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=customer_df[target]\n",
    "\n",
    "Xs = pd.get_dummies(customer_df[possible_predictors],drop_first=True)\n",
    "Xs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN can handle missing values, so we keep them as missing not to create bias in the data.\n",
    "\n",
    "However, the case of missing vlause for pdays is different. The values are not missing for our lack of knowlege, but they are missing for a difference about the population of data object that leads to them not having a value. In these situations, we will use MM method to fill the missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MM method\n",
    "\n",
    "we will fill the missing values with Max+Mean (MM) of the attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs.pdays.fillna(Xs.pdays.max()+Xs.pdays.mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs.pdays.plot(kind='hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize data\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "scaler.fit(Xs)  # Note the use of an array of column names\n",
    "\n",
    "Xs = pd.DataFrame(scaler.transform(Xs),columns =Xs.columns)\n",
    "Xs.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up experimentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(Xs,y,  test_size=0.3)\n",
    "\n",
    "print(X_train.shape,X_test.shape,y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=1000)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "importances = rf.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in rf.estimators_], axis=0)\n",
    "\n",
    "df = pd.DataFrame({'feature': X_train.columns, 'importance': importances, 'std': std})\n",
    "df = df.sort_values('importance')\n",
    "print(df)\n",
    "\n",
    "ax = df.plot(kind='barh', xerr='std', x='feature', legend=False)\n",
    "ax.set_ylabel('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_features=df[df.importance>=0.01].feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier().fit(X_train[select_features], y_train)\n",
    "predict_y = knn.predict(X_test[select_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contigency = pd.crosstab(y_test,predict_y)\n",
    "contigency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = contigency['yes']['yes']\n",
    "TN = contigency['no']['no']\n",
    "FP = contigency['yes']['no']\n",
    "FN = contigency['no']['yes']\n",
    "n = contigency.sum().sum()\n",
    "\n",
    "Acuracy = (TP + TN)/n\n",
    "Recall = TP/(TP+FN)\n",
    "Precision = TP/(TP+FP)\n",
    "FScore = 2*Recall*Precision/(Recall+Precision)\n",
    "print('Accuracy= {}.'.format(Acuracy))\n",
    "print('Recall= {}.'.format(Recall))\n",
    "print('Precision= {}.'.format(Precision))\n",
    "print('FScore= {}.'.format(FScore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateBinaryClassification(predictions, actuals):\n",
    "    contigency = pd.crosstab(actuals,predictions)\n",
    "    TP = contigency['yes']['yes']\n",
    "    TN = contigency['no']['no']\n",
    "    FP = contigency['yes']['no']\n",
    "    FN = contigency['no']['yes']\n",
    "    n = contigency.sum().sum()\n",
    "\n",
    "    Acuracy = (TP + TN)/n\n",
    "    Recall = TP/(TP+FN)\n",
    "    Precision = TP/(TP+FP)\n",
    "    FScore = 2*Recall*Precision/(Recall+Precision)\n",
    "    \n",
    "    return Acuracy, Recall, Precision, FScore\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluateBinaryClassification(predict_y,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune KNN\n",
    "Parameters: \n",
    "\n",
    "    n_neighborsint, default=5\n",
    "    Number of neighbors to use by default for kneighbors queries.\n",
    "\n",
    "    weights{‘uniform’, ‘distance’} default=’uniform’\n",
    "    weight function used in prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create tuning (validation) set: devide the trainset\n",
    "\n",
    "X_train_s, X_tune, y_train_s, y_tune = train_test_split(X_train, y_train, test_size=0.3)\n",
    "\n",
    "print('X_train Shape: ', X_train.shape)\n",
    "print('y_train Shape: ', y_train.shape)\n",
    "\n",
    "print('X_train_s Shape: ', X_train_s.shape)\n",
    "print('X_tune Shape: ', X_tune.shape)\n",
    "print('y_train_s Shape: ', y_train_s.shape)\n",
    "print('y_tune Shape: ', y_tune.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a placeholder for experimentations\n",
    "num_repetition=1\n",
    "\n",
    "n_neighbors_options = range(1,10)\n",
    "weights_options  = ['uniform','distance']\n",
    "\n",
    "my_index = pd.MultiIndex.from_product([n_neighbors_options,weights_options],\n",
    "                                     names=('n_neighbors', 'weights'))\n",
    "\n",
    "tune_df = pd.DataFrame(index = my_index,\n",
    "                       columns=['R{}'.format(i) for i in range(num_repetition)])\n",
    "\n",
    "tune_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for neighbor_o in n_neighbors_options:\n",
    "    for weights_o in weights_options:\n",
    "        for rep in tune_df.columns:\n",
    "            knn = KNeighborsClassifier(n_neighbors=neighbor_o,weights=weights_o)\n",
    "            knn.fit(X_train_s[select_features], y_train_s)\n",
    "            predict_y = knn.predict(X_tune[select_features])\n",
    "            metrics = evaluateBinaryClassification(predict_y,y_tune)\n",
    "            \n",
    "            #tune based on precision\n",
    "            tune_df.at[(neighbor_o,weights_o),rep] = metrics[1]\n",
    "        print(neighbor_o,weights_o)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tune_df.sort_values('R0',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuned KNN\n",
    "Use the tune KNN to Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=1,weights='uniform').fit(X_train[select_features], y_train)\n",
    "predict_y = knn.predict(X_test[select_features])\n",
    "evaluateBinaryClassification(predict_y,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(y_test,predict_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(np.random.permutation(len(y_test))<1000).replace({False:'no',True:'yes'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comapre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Methods = ['Random','KNN']\n",
    "Metrics = ['Accuracy','Recall','Precision','Fscore']\n",
    "\n",
    "compare_df = pd.DataFrame(index = Methods, columns = Metrics)\n",
    "\n",
    "#Method1 #KNN\n",
    "\n",
    "compare_df.loc['KNN'] = evaluateBinaryClassification(predict_y,y_test)\n",
    "\n",
    "number_Yes =  np.sum(predict_y=='yes')\n",
    "\n",
    "#Method 2 Random\n",
    "predict_y = pd.Series(np.random.permutation(len(y_test))<number_Yes).replace({False:'no',True:'yes'})\n",
    "print(evaluateBinaryClassification(predict_y,y_test))\n",
    "\n",
    "compare_df.loc['Random'] = evaluateBinaryClassification(predict_y,y_test)\n",
    "compare_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
