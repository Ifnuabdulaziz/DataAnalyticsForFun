{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayesian (kNN)\n",
    "\n",
    "## Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateBinaryClassification(predictions, actuals):\n",
    "    contigency = pd.crosstab(actuals,predictions)\n",
    "    TP = contigency['yes']['yes']\n",
    "    TN = contigency['no']['no']\n",
    "    FP = contigency['yes']['no']\n",
    "    FN = contigency['no']['yes']\n",
    "    n = contigency.sum().sum()\n",
    "\n",
    "    Acuracy = (TP + TN)/n\n",
    "    Recall = TP/(TP+FN)\n",
    "    Precision = TP/(TP+FP)\n",
    "    FScore = 2*Recall*Precision/(Recall+Precision)\n",
    "    \n",
    "    return Acuracy, Recall, Precision, FScore\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_df = pd.read_csv('Customer Subscription.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First let's do KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deal with unknowns\n",
    "customer_df.job.replace('unknown',np.nan,inplace=True)\n",
    "customer_df.marital.replace('unknown',np.nan,inplace=True)\n",
    "customer_df.education.replace('unknown',np.nan,inplace=True)\n",
    "customer_df.loan.replace('unknown',np.nan,inplace=True)\n",
    "customer_df.default.replace('unknown',np.nan,inplace=True)\n",
    "customer_df.job.replace('unknown',np.nan,inplace=True)\n",
    "customer_df.housing.replace('unknown',np.nan,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_df.pdays.replace(999,np.nan,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task: Classificaiton\n",
    "\n",
    "We would like to predict the class (subscriber/ no subscriber) of customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_predictors = ['age', 'job', 'marital', 'education', 'default', 'housing', 'loan',\n",
    "       'contact', 'month', 'day_of_week', 'duration', 'campaign', 'pdays',\n",
    "       'previous', 'poutcome']\n",
    "target = 'y'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kNN Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=customer_df[target]\n",
    "\n",
    "Xs = pd.get_dummies(customer_df[possible_predictors],drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN can handle missing values, so we keep them as missing not to create bias in the data.\n",
    "\n",
    "However, the case of missing vlause for pdays is different. The values are not missing for our lack of knowlege, but they are missing for a difference about the population of data object that leads to them not having a value. In these situations, we will use MM method to fill the missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MM method\n",
    "\n",
    "we will fill the missing values with Max+Mean (MM) of the attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs.pdays.fillna(Xs.pdays.max()+Xs.pdays.mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize data\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "scaler.fit(Xs)  # Note the use of an array of column names\n",
    "\n",
    "Xs = pd.DataFrame(scaler.transform(Xs),columns =Xs.columns)\n",
    "Xs.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up experimentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(Xs,y,  test_size=0.3,random_state=1)\n",
    "\n",
    "print(X_train.shape,X_test.shape,y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=1000,random_state=2)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "importances = rf.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in rf.estimators_], axis=0)\n",
    "\n",
    "df = pd.DataFrame({'feature': X_train.columns, 'importance': importances, 'std': std})\n",
    "df = df.sort_values('importance')\n",
    "print(df)\n",
    "\n",
    "ax = df.plot(kind='barh', xerr='std', x='feature', legend=False)\n",
    "ax.set_ylabel('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_features=df[df.importance>=0.05].feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuned KNN\n",
    "Use the tune KNN to Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=1,weights='uniform').fit(X_train[select_features], y_train)\n",
    "y_predict_knn = knn.predict(X_test[select_features])\n",
    "pd.crosstab(y_test,y_predict_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluateBinaryClassification(y_predict_knn,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comapre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Methods = ['Random','KNN','NB']\n",
    "Metrics = ['Accuracy','Recall','Precision','Fscore']\n",
    "\n",
    "compare_df = pd.DataFrame(index = Methods, columns = Metrics)\n",
    "\n",
    "#Method1 #KNN\n",
    "\n",
    "compare_df.loc['KNN'] = evaluateBinaryClassification(y_predict_knn,y_test)\n",
    "\n",
    "number_Yes =  np.sum(y_predict_knn=='yes')\n",
    "\n",
    "#Method 2 Random\n",
    "y_predict_random = pd.Series(np.random.permutation(len(y_test))<number_Yes).replace({False:'no',True:'yes'})\n",
    "print(evaluateBinaryClassification(y_predict_random,y_test))\n",
    "\n",
    "compare_df.loc['Random'] = evaluateBinaryClassification(y_predict_random,y_test)\n",
    "compare_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayesian\n",
    "\n",
    "## Preprocess\n",
    "\n",
    "NB can also handle missing values, but it does not need the data to be standardized. So some of the preprocessing steps will look different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=customer_df[target]\n",
    "\n",
    "Xs = Xs = pd.get_dummies(customer_df[possible_predictors],drop_first=True)\n",
    "Xs.pdays.fillna(Xs.pdays.max()+Xs.pdays.mean(),inplace=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xs,y,  test_size=0.3,random_state=1)\n",
    "print(X_train.shape,X_test.shape,y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the same features we selected using Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train[select_features], y_train)\n",
    "\n",
    "y_predict_nb = nb.predict(X_test[select_features])\n",
    "pd.crosstab(y_test,y_predict_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluateBinaryClassification(y_predict_nb,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_df.loc['NB'] = evaluateBinaryClassification(y_predict_nb,y_test)\n",
    "compare_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Random Method number of yes prediction: {}'.format(np.sum(y_predict_random=='yes')))\n",
    "print('KNN Method number of yes prediction: {}'.format(np.sum(y_predict_knn=='yes')))\n",
    "print('NB Method number of yes prediction: {}'.format(np.sum(y_predict_nb=='yes')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict probabilities\n",
    "y_prob = nb.predict_proba(X_test[select_features])\n",
    "y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df = pd.concat([pd.DataFrame({'actual': y_test, 'predicted': y_predict_nb}),\n",
    "                pd.DataFrame(y_prob, index=y_test.index,columns = ['No_prob','Yes_prob'])], axis=1)\n",
    "summary_df.sort_values('Yes_prob',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Thresholds = np.linspace(0.9999999,1,10)\n",
    "\n",
    "for tr in Thresholds:\n",
    "    BM = summary_df.Yes_prob > tr\n",
    "    print('Number of Yes for threshold {} is {}.'.format(tr,np.sum(BM)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_nb = pd.Series(summary_df.Yes_prob>0.9999999222222222).replace({False:'no',True:'yes'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Random Method number of yes prediction: {}'.format(np.sum(y_predict_random=='yes')))\n",
    "print('KNN Method number of yes prediction: {}'.format(np.sum(y_predict_knn=='yes')))\n",
    "print('NB Method number of yes prediction: {}'.format(np.sum(y_predict_nb=='yes')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_df.loc['NB'] = evaluateBinaryClassification(y_predict_nb,y_test)\n",
    "compare_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
